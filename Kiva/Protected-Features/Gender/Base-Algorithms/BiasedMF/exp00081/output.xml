<experiment count="81">
  <!--DO NOT EDIT. File automatically generated by librec-auto-->
  <meta>
    <param>
      <name>learn-rate-max</name>
      <value>0.06298165805853304</value>
    </param>
    <param>
      <name>user-reg</name>
      <value>0.7397605666872276</value>
    </param>
    <param>
      <name>item-reg</name>
      <value>0.2619757613875324</value>
    </param>
    <param>
      <name>num-factors</name>
      <value>5</value>
    </param>
  </meta>
  <statuses>
    <status>
      <message>Executing</message>
      <exp_no>81</exp_no>
      <date>2022-06-05 15:53:15.762565</date>
    </status>
    <status>
      <message>Completed</message>
      <date>2022-06-05 15:53:20.248427</date>
    </status>
    <status>
      <message>Python-side metrics completed</message>
      <date>2022-06-05 15:54:13.687679</date>
    </status>
  </statuses>
  <results>
    <folds>
      <cv id="1">
        <metric name="NormalizedDCGEvaluator">0.05437472888321479</metric>
        <metric name="ndcg_metric.py">0.05309506953793477</metric>
      </cv>
      <cv id="2">
        <metric name="NormalizedDCGEvaluator">0.05978687877567753</metric>
        <metric name="ndcg_metric.py">0.05278812493323645</metric>
      </cv>
      <cv id="3">
        <metric name="NormalizedDCGEvaluator">0.05478143433991633</metric>
        <metric name="ndcg_metric.py">0.0581302384531628</metric>
      </cv>
    </folds>
    <averages>
      <metric name="NormalizedDCGEvaluator">0.05631434733293622</metric>
      <metric name="ndcg_metric.py">0.05467114430811134</metric>
    </averages>
  </results>
</experiment>
